---
tags:
  - YAML
  - deploy
  - AzurePipelines
  - AzureDevops
  - librerie
  - release
  - build
---


mercoledi

ho da fare: 
1. stesura del wiki contenente istruzioni del leggimi.txt su deploy/kubernetes di VFF
2. ricerca sulle pipelines di release per VVF

wiki.
testo √®:

```
Istruzioni per il deploy di un container su AKS
Servono: 
- ‚ÄÉAZ installato in locale
- ‚ÄÉKubectl installato in locale
-‚ÄÉ‚ÄÉil nome del servizio: ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉAKS-VVF-Dev
-‚ÄÉ‚ÄÉil resource group:‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ  AFM-VVF-rg-01
- ‚ÄÉil nome del registry:‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ afmvvf.azurecr.io
- ‚ÄÉil nome dell'oggetto pubblicato sul registry:‚ÄÉ‚ÄÉafmvvf.azurecr.io/vvf_afm_frontend:latest

---opzionale, gi√† fatto per attachments
		(forse questo si fa soltanto la prima volta)
		Collegarsi al portale e innalzare i privilegi sul proprio ruolo 
		‚ÄÉ‚ÄÉ-‚ÄÉ‚ÄÉHome --> Identity Governance --> Privileged Identity Management --> Microsoft Entra Roles
		‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ --> Una volta che sei qua clicca su ‚ÄúPrivileged Identity Management‚Äù nella barra dei link superiore:

		Collegamento tra AKS e ACR:
		az aks update --name AKS-VVF-Dev --resource-group AFM-VVF-rg-01 --attach-acr afmvvf

		Recupero delle credenziali del cluster - serve a configurare kubectl locale
		in modo che punti ai server della subscription Azure anzich√© quelli di OKD
		az aks get-credentials --resource-group AFM-VVF-rg-01 --name AKS-VVF-Dev
---

Entra in VPN Azure, altrimenti non trova i server di kubernetes
- Creazione disco tramite Azure
‚ÄÉ‚ÄÉaz disk create --resource-group AFM-VVF-rg-01 --name afmvvf_frontend --size-gb 1

- Verifica del disco
az disk show `
  --resource-group AFM-VVF-rg-01 `
  --name afmvvf_frontend `
  --query "{diskName:name, diskResourceId:id}" `
  -o json
  
-- Crea il PV su Kubernetes:
‚ÄÉ‚ÄÉ- carica il file yaml di deploy vvf-fe-pv.yaml
‚ÄÉ‚ÄÉkubectl apply -f vvf-fe-pv.yaml
‚ÄÉ‚ÄÉ- carica il file per la creazione del Persistent Volume Claim
‚ÄÉ‚ÄÉkubectl apply -f vvf-fe-pvc.yaml
‚ÄÉ‚ÄÉ- aggiungi il volume al file di deploy

- Carica la ConfigMap con il file di configurazione (solo BE; no FE)
kubectl create configmap vvf-fe-config --from-file=appsettings.json

- Crea la ConfigMap
kubectl apply -f vvf-fe-configmap.yaml

- Crea il file di deploy
... vedi yaml a parte: vvf-fe-deployment.yaml

- Valida il deploy
kubectl apply --dry-run=client --validate=true -f vvf-fe-deployment.yaml

- Applica il deploy
kubectl apply -f vvf-fe-deployment.yaml

- Crea il servizio
kubectl apply -f vvf-fe-svc.yaml

- Verifica
kubectl get pods
kubectl get svc

- Check del pod:
kubectl describe pod <nome-pod>(da verificare recuperando numero servizio dalla get pods)

- Verifica dell'ultimo log generato prima dello schianto
kubectl logs <nome-pod> --previous

- oppure, verifica specifico container
kubectl logs <nome-pod> -c <nome-container>

- riduzione del numero di repliche del deploy a zero (per fermare i pod in loopback)
kubectl scale deployment <nome-pod> --replicas=0

-- ripristino
kubectl scale deployment <nome-pod> --replicas=1

-- Verifica errore dell'init container:
kubectl logs <nome-pod> -c init-copy-config -n default


-- Cancellazione di un pod:
kubectl delete pod <nome-pod>


-- Verifica

```

diventa: 
Ecco la versione **ordinata, in Markdown, stile Wiki**, mantenendo la struttura, ma **generalizzando i nomi** e indicando gli esempi solo quando servono.

---

# üì¶ Deploy di un Container su AKS

## üìå Prerequisiti

Servono installati in locale:

* **Azure CLI**
* **kubectl**

Parametri richiesti:

| Parametro           | Esempio                                 |
| ------------------- | --------------------------------------- |
| Nome servizio AKS   | `AKS-Dev`                               |
| Resource Group      | `RG-Dev-01`                             |
| Container Registry  | `myregistry.azurecr.io`                 |
| Immagine pubblicata | `myregistry.azurecr.io/frontend:latest` |

---

## üîê (Opzionale) Elevazione privilegi

Questa attivit√† potrebbe essere necessaria solo al primo deploy.

Percorso:

```
Home ‚Üí Identity Governance ‚Üí Privileged Identity Management ‚Üí Microsoft Entra Roles
```

> Una volta entrati, selezionare **Privileged Identity Management** dalla barra superiore e attivare il ruolo richiesto.

---

## ü§ù Collegamento AKS ‚áÑ ACR

```bash
az aks update --name <nome-servizio-AKS> \
              --resource-group <nome-resource-group> \
              --attach-acr <nome-acr>
```

---

## üîë Recupero credenziali Cluster

Serve per configurare `kubectl` in modo che punti ad Azure:

```bash
az aks get-credentials --resource-group <nome-resource-group> \
                       --name <nome-servizio-AKS>
```

---

## üåê Connessione VPN

> **Obbligatorio**: connettersi alla VPN aziendale prima del deploy, altrimenti Kubernetes non √® raggiungibile.

---

## üíΩ Creazione Storage (PV / PVC)

### 1. Creazione disco su Azure

```bash
az disk create --resource-group <nome-resource-group> \
               --name <nome-disco> \
               --size-gb <dimensione>
```

### 2. Verifica del disco

```bash
az disk show \
  --resource-group <nome-resource-group> \
  --name <nome-disco> \
  --query "{diskName:name, diskResourceId:id}" \
  -o json
```

### 3. Deploy Persistent Volume

```bash
kubectl apply -f pv.yaml
```

### 4. Deploy Persistent Volume Claim

```bash
kubectl apply -f pvc.yaml
```

> Assicurarsi di collegare il volume nel relativo file `deployment.yaml`.

---

## üìë ConfigMap

> Esempio riferito al backend. Il frontend potrebbe non richiederla.

### Creazione ConfigMap da file

```bash
kubectl create configmap <nome-config> --from-file=appsettings.json
```

### Oppure tramite file YAML

```bash
kubectl apply -f configmap.yaml
```

---

## üöÄ Deployment

### Validazione

```bash
kubectl apply --dry-run=client --validate=true -f deployment.yaml
```

### Applicazione definitiva

```bash
kubectl apply -f deployment.yaml
```

---

## üåç Creazione del Servizio

```bash
kubectl apply -f service.yaml
```

---

## üîç Verifiche

```bash
kubectl get pods
kubectl get svc
```

### Dettaglio pod

```bash
kubectl describe pod <nome-pod>
```

### Log ultimo crash

```bash
kubectl logs <nome-pod> --previous
```

### Log di uno specifico container

```bash
kubectl logs <nome-pod> -c <nome-container>
```

---

## üõë Gestione Repliche

### Riduzione a zero (per loop o errori continui)

```bash
kubectl scale deployment <nome-deploy> --replicas=0
```

### Ripristino

```bash
kubectl scale deployment <nome-deploy> --replicas=1
```

---

## üß∞ Troubleshooting

### Errore init container

```bash
kubectl logs <nome-pod> -c <nome-init-container> -n default
```

### Cancellazione Pod

```bash
kubectl delete pod <nome-pod>
```

---

## üìù Note

* I file YAML indicati (`pv.yaml`, `pvc.yaml`, `deployment.yaml`, `service.yaml`, `configmap.yaml`) devono essere gi√† presenti nella repository del progetto.
* Gli esempi specifici sono riferiti al **frontend**, ma la procedura √® valida per qualsiasi componente containerizzato.






## pipeline.yaml di partnumbers:
##### Checklist da ricontrollare

[ ] DOCKER_USERNAME e DOCKER_PASSWORD esistono nella pipeline o nel Variable Group.

[ ] Il repository Docker (vvf-afm-partnumbers) √® gi√† presente nell‚ÄôACR.



# **Pipeline di Release**

*Pipeline di rilascio classiche*
Le pipeline di rilascio classiche forniscono agli sviluppatori un framework per **distribuire** le applicazioni in pi√π ambienti in modo efficiente e sicuro. 
Utilizzando le pipeline di rilascio, √® possibile automatizzare i processi di test e distribuzione, impostare strategie di distribuzione flessibili, incorporare flussi di lavoro di approvazione e garantire transizioni fluide delle applicazioni nelle varie fasi.

*Come funzionano le pipeline di rilascio?*
Come parte di ogni distribuzione, Azure Pipelines esegue i seguenti passaggi:
1. Approvazione pre-distribuzione :
	Quando viene attivata una nuova richiesta di distribuzione (release), Azure Pipelines verifica se √® necessaria un'approvazione preliminare prima di distribuire una release in una fase specifica. 
	Se l'approvazione √® necessaria, invia notifiche via email ai responsabili dell'approvazione interessati; Garantisce in questo modo che solo le release autorizzate avanzino alla fase successiva.

2. Lavoro di distribuzione della coda :
	Azure Pipelines pianifica il processo di distribuzione su un agente disponibile, che eseguir√† tutte le attivit√† necessarie.

3. Selezione dell'agente :
	Un agente disponibile si occupa del processo di distribuzione ([[2025-11-27#Release dell‚Äôartefatto (deploy)|deployment]]). 
	√à possibile configurare una pipeline di rilascio per selezionare dinamicamente un agente idoneo durante l'esecuzione.

4. Dowload degli artefatti :
	L'agente recupera e scarica tutti gli artefatti specificati nella release (file di build, pacchetti, configurazioni, ecc.).

5. Eseguire le attivit√† di distribuzione :
	L‚Äôagente esegue tutte le attivit√† configurate, come installazioni, configurazioni, migrazioni di database, test automatizzati, ecc.

6. Genera registri di avanzamento :
	L'agente genera registri completi per ogni fase della distribuzione e li invia ad Azure Pipelines.
	Ogni fase produce log completi che vengono inviati ad Azure Pipelines.
	Permette di monitorare lo stato del deployment e di diagnosticare eventuali errori.

7. Approvazione post-distribuzione :
	Al termine della distribuzione in una fase, Azure Pipelines verifica se √® necessaria un'approvazione post-distribuzione per quella specifica fase. Se non √® necessaria alcuna approvazione, o una volta ottenuta l'approvazione richiesta, procede con l'avvio della distribuzione alla fase successiva.

![[Pasted image 20251210113914.png]]

*Modello di distribuzione*
Le pipeline di rilascio di Azure supportano un'ampia gamma di fonti di artefatti, tra cui Jenkins, Azure Artifacts e Team City. 
L'esempio seguente illustra un modello di distribuzione che utilizza le pipeline di rilascio di Azure:
Nell'esempio seguente, la pipeline √® composta da due artefatti di build provenienti da pipeline di build separate. L'applicazione viene inizialmente distribuita nella fase di sviluppo e poi in due fasi di controllo qualit√† separate . 
Se la distribuzione ha esito positivo in entrambe le fasi di controllo qualit√†, l'applicazione verr√† distribuita nel Prod ring 1 e poi nel Prod ring 2. Ogni anello di produzione rappresenta pi√π istanze della stessa app web, distribuite in diverse sedi in tutto il mondo.
Questo approccio permette test progressivi e riduce il rischio di errori in produzione.
![[Pasted image 20251210113936.png]]


*Rilasci vs distribuzioni*

Una #release √® un **costrutto** che contiene un **set di artefatti** con versione specificata (in una pipeline). 
Include uno snapshot di tutte le informazioni necessarie per eseguire tutte le attivit√† e le azioni nella pipeline di release, come fasi, attivit√†, criteri come trigger e responsabili dell'approvazione e opzioni di distribuzione. Possono essere presenti pi√π release da una pipeline di release e le informazioni su ciascuna di esse vengono archiviate e visualizzate in Azure Pipelines per il periodo di conservazione specificato .

Un #deployment √® **l'azione di esecuzione** delle attivit√† per una fase, che pu√≤ includere l'esecuzione di test automatizzati, il deployment di artefatti di build e qualsiasi altra azione specificata per quella fase. 
L'avvio di una release avvia ogni deployment in base alle impostazioni e ai criteri definiti nella pipeline di release originale. Possono essere eseguiti pi√π deployment di ogni release anche per una sola fase. 
>Una release pu√≤ avere pi√π deployment per ciascuna fase, e i deployment possono essere ripetuti in caso di errori.


una  release √® come un pacchetto completo che contiene artefatti e tutte le informazioni necessarie per distribuire l'applicazione. 
- una **fase** √® un'ambiente in cui distribuire la release, ad esempio sviluppo, qa, o produzione.
- in una fase, puoi decidere di eseguire pi√π deployment della stessa release. ad esempio:
	- distribuisci la release in QA per un gruppo di test interni.
	- poi la ridistribuisci nello stesso QA con configurazioni diverse o dopo una correzione minima.
questo permette flessibilit√† e testing progressivo senza creare una nuova release.

Quando il deployment di una release fallisce per una fase, √® possibile ridistribuire la stessa release in quella fase. 
Per ridistribuire una release, √® sufficiente accedere alla release che si desidera distribuire e selezionare "Distribuisci".


Il diagramma seguente mostra la relazione tra rilascio, pipeline di rilascio e distribuzioni.
###### diagramma
![[Pasted image 20251210113954.png]]



### _come si scrive una pipeline di release?_
>prima build ‚Üí poi release. Non esiste release senza artefatti.

Perfetto, sorella üòé, adesso ti spiego passo passo **come creare e gestire una pipeline di release in Azure DevOps**, con tutti i dettagli pratici.

---

# **Creare una Pipeline di Release in Azure DevOps**

*Prerequisiti*
Prima di iniziare, devi avere:
* Una o pi√π **pipeline di build** gi√† configurate che producano artefatti (es. pacchetti, file di applicazione, librerie).
* Agenti di build/distribuzione disponibili (self-hosted o Microsoft-hosted).
* Accessi agli ambienti di destinazione (dev, QA, prod).

*Creare una nuova pipeline di release
1. Vai su Pipelines ‚Üí Releases in Azure DevOps.
2. Clicca su New pipeline.
3. Scegli un template vuoto o uno predefinito (es. ‚ÄúAzure App Service deployment‚Äù).
4. Dai un nome alla release pipeline

*Configurare gli artefatti*
1. Clicca su Add an artifact.
2. Seleziona la source (pipeline di build, repository o feed).
3. Specifica la versione o lascia ‚ÄúLatest‚Äù per prendere sempre l‚Äôultima build.
4. Salva l‚Äôartefatto.
Puoi aggiungere pi√π artefatti se la release dipende da build diverse (es. backend + frontend).

*Creare le fasi (environments)*

Ogni fase rappresenta un ambiente dove distribuire la release:
1. Clicca su Add an environment.
2. Dai un nome 
3. Scegli il tipo di deploy (es. Azure App Service, Virtual Machine, **Kubernetes**).
###### *esempi*
* **Dev:** distribuzione rapida per test interni.
* **QA:** distribuzione controllata per test approfonditi.
* **Prod Ring 1 e Ring 2:** distribuzione graduale in produzione (canary deployment).

##
*Configurare le attivit√† di deployment

1. All‚Äôinterno di ogni fase, clicca su **Tasks**.
2. Aggiungi attivit√† come:
   * Copia dei file
   * Deploy su Azure App Service / VM / Container
   * Esecuzione di script PowerShell o Bash
   * Test automatizzati (unit, integrazione, UI)
3. Configura eventuali variabili di ambiente o segreti.

 *Configurare approvazioni e criteri

**Approvazioni pre-distribuzione**
* Vai alla fase ‚Üí Pre-deployment conditions ‚Üí Approvals.
* Aggiungi i responsabili che devono approvare il deploy prima che inizi.
* Puoi anche impostare timeout e notifiche.

**Approvazioni post-distribuzione**
* Vai alla fase ‚Üí Post-deployment conditions ‚Üí Approvals.
* Utile per verificare manualmente lo stato prima di passare alla fase successiva.

**Criteri aggiuntivi**
* Gates: controlli automatici prima del deploy (ad esempio test di qualit√†, monitoring, metriche di performance).
* Triggers: puoi attivare il deploy automaticamente quando arriva un nuovo artefatto.

*Eseguire la release*

1. Clicca su 'Create release'.
2. Seleziona la versione degli artefatti da distribuire.
3. Scegli le fasi in cui distribuire.
4. Clicca su 'Create' ‚Üí il deployment inizier√† secondo le condizioni impostate.

---
*Monitoraggio e gestione dei deployment*

* Durante l‚Äôesecuzione, puoi monitorare lo stato del deployment in tempo reale.
* Ogni fase genera log dettagliati, visibili in Azure DevOps.
* In caso di errore, puoi ridistribuire la stessa release senza creare una nuova build.
* Puoi anche tracciare pi√π deployment per la stessa release.

*Best practice
* Usa nomi chiari per fasi e release.
* Automatizza quanto pi√π possibile con script e test.
* Configura approvazioni e gates per ambienti critici (QA, Prod).
* Mantieni tracciabilit√†: ogni release deve essere collegata ai log dei deployment.
* Considera strategie di distribuzione progressive per Prod (canary, blue-green).

Perfetto sorella üòé, vediamo di chiarire bene con esempi concreti.

---

# **Pipeline di Build**

La **pipeline di build** serve a **automatizzare tutto ci√≤ che normalmente faresti a mano per ‚Äúcostruire‚Äù un‚Äôapplicazione**.

### **Esempi di operazioni che una pipeline di build automatizza:**

1. **Compilazione del codice**

   * Manuale: apri Visual Studio / IDE, clicchi ‚ÄúBuild‚Äù ‚Üí genera DLL o eseguibili.
   * Pipeline: il sistema esegue automaticamente la compilazione ad ogni commit o push sul repository.

2. **Esecuzione dei test automatici**

   * Manuale: apri la suite di test, esegui test unitari e di integrazione.
   * Pipeline: il sistema esegue automaticamente tutti i test e segnala errori.

3. **Creazione degli artefatti**

   * Manuale: prendi i file generati (binari, librerie, pacchetti) e li copi in una cartella o li comprimi in un ZIP.
   * Pipeline: il sistema crea automaticamente un artefatto pronto per la release.

4. **Controllo della qualit√† del codice**

   * Manuale: esegui analisi statiche, linting o verifiche di codice.
   * Pipeline: strumenti come SonarQube o ESLint vengono eseguiti automaticamente.

5. **Versionamento**

   * Manuale: aggiorni numeri di versione o tag nel codice.
   * Pipeline: incrementa automaticamente versioni di build, crea tag Git e registra metadati.

---

# **Equivalente della Pipeline di Release**

Se la pipeline di build √® il **‚Äúfare il pacchetto‚Äù**, la **pipeline di release √® il ‚Äúconsegnare il pacchetto agli ambienti‚Äù**.

### **Esempi di operazioni che una pipeline di release automatizza:**

1. **Distribuzione dell‚Äôartefatto negli ambienti**

   * Manuale: copi i file da dev a QA, poi a prod, tramite FTP o script.
   * Pipeline: Azure Pipelines li distribuisce automaticamente negli ambienti configurati.

2. **Configurazioni ambientali**

   * Manuale: cambi variabili di connessione o configurazioni specifiche per QA o Prod.
   * Pipeline: imposta automaticamente le variabili per ogni fase.

3. **Esecuzione di script post-deploy**

   * Manuale: apri un terminale e lanci script di migrazione DB o setup.
   * Pipeline: tutto viene eseguito automaticamente e registrato.

4. **Approvazioni e gates**

   * Manuale: chiedi a un responsabile se puoi distribuire in Prod.
   * Pipeline: invia notifiche, richiede approvazioni e passa solo se le condizioni sono soddisfatte.

5. **Monitoraggio e rollback**

   * Manuale: controlli i log e ridistribuisci manualmente se qualcosa va storto.
   * Pipeline: registra tutto automaticamente e permette di ridistribuire o annullare facilmente.

---
 **In sintesi:**

| Pipeline    | Scopo                                   | Esempi manuali                                                                         | Automatizzato                                                              |
| ----------- | --------------------------------------- | -------------------------------------------------------------------------------------- | -------------------------------------------------------------------------- |
| **Build**   | Creare il pacchetto dell‚Äôapplicazione   | Compilare codice, eseguire test, creare ZIP/artefatti                                  | Compilazione automatica, test automatici, artefatti pronti                 |
| **Release** | Distribuire il pacchetto negli ambienti | Copiare file in QA/Prod, configurare variabili, eseguire script, chiedere approvazioni | Deploy automatico, variabili per ambiente, approvazioni, logging, rollback |

---

Se vuoi, sorella, posso farti **un esempio pratico completo**: dalla build alla release con artefatti, per vedere tutto il flusso come se lo stessi facendo in Azure DevOps. Vuoi che lo faccia?











scoperta sugli stages delle pipelines di build:
noti che se ‚Äúsegmenti‚Äù gli stage o i task in pi√π fasi/pipeline, la Docker multi-arch build fallisce con l' errore:

```
Multi-platform build is not supported for the docker driver
```

Questo succede per un motivo tecnico preciso:

### **Cosa cambia tra ‚Äúunificato‚Äù e ‚Äúsegmentato‚Äù**
con la pipeline unificata 
* Tutti i comandi Docker vengono eseguiti all‚Äôinterno dello stesso job e nello stesso contesto di Docker.
* Il builder Buildx creato (`docker buildx create --use`) rimane attivo per tutta la durata del job.
* QEMU viene installato e il driver container viene effettivamente utilizzato.

con la Pipeline segmentata o job separato
* Quando spezzetti gli stage in pi√π job o separi in pi√π step che finiscono e ricominciano in un nuovo job, succede che:
  1. Il builder Buildx creato nel job precedente **non** √® pi√π disponibile.
  2. Lo step successivo parte con il driver Docker predefinito, che spesso √® `docker` (non `docker-container`) su `ubuntu-latest`.
  3. Buildx tenta di fare multiarch, ma il driver non lo supporta ‚Üí errore.

In pratica: **Buildx multiarch richiede un builder attivo in quel job**. Se cambi job o stage, devi ricrearlo o non funziona.

---

## üîπ Perch√© non basta usare lo stesso agente

* Anche se l‚Äôagente √® lo stesso (`ubuntu-latest`), **ogni job ha un contesto Docker separato**.
* Docker su hosted agent non mantiene lo stato tra job.
* Il driver predefinito ricade su `docker`, che **non supporta multiarch**.

---

## **Come farlo funzionare anche in pipeline segmentata**

Ci sono due soluzioni principali:

1. Creare il builder Buildx in ogni job che fa build multiarch

```yaml
- script: |
    docker run --privileged --rm tonistiigi/binfmt --install all
    docker buildx create --name mybuilder --driver docker-container --use
    docker buildx inspect --bootstrap
  displayName: 'Setup Buildx per multiarch'
```

* **Importante:** devi usare `--driver docker-container`.
* Poi puoi fare il `docker buildx build --platform ...` nello stesso job.

 2. Usare **un unico job** per tutti i passaggi Docker

* Come nella pipeline ‚Äúunificata‚Äù, eviti di ricreare il builder e multiarch funziona senza problemi.

---

### üîπ Conclusione

* Il motivo per cui ‚Äúunificata‚Äù funziona e ‚Äúsegmentata‚Äù no **non √® il codice YAML**, n√© l‚Äôagente, ma:

  1. Lo **stato di Docker Buildx** non persiste tra job/stage.
  2. Buildx usa il **driver predefinito `docker`**, che **non supporta multiarch**, se il builder non viene creato nel job corrente.

* Quindi, se vuoi mantenere pipeline segmentata, devi **ricreare Buildx con `docker-container` in ogni job** che fa build multiarch.

---


!! correggi il wiki di stamattina e metti il redcupero delle credenziali fuori... (non nell'opzionale)
noi dobbaimo iniziare con la creazione nel punto 3