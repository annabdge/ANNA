---
tags:
  - serviceconnection
aliases:
---

questa mattina dopo aver fatto l'accesso all'account microsoft azienzale e il collegamento a teams, studio la documentazione fornitami dal mio tutor riguardo DevOps. 
uno riguardante le istruzioni per il rilascio OKD di teseo. (fatta oggi [[2025-12-02|2 dicembre]]) 
l'altro su i concetti gia visti in concreto nei giorni scorsi sul funzionamento di azure devops.

studio documentazione.
##### solid
mella programmzione ad oggetti (e anch in quella softwaew agile) vige il principio solid:
-s . srp(principio di responsabilita unica)
-o . ocp(principio aperto-chiuso, allargabile ma non modificabile)
-l . liskov(le funzioni che utilizzano puntatori o riferimenti a classi base devono essere in grado di utilizzare oggetti di classi derivate senza saperlo.)
-i . isp(segregazione dell'interfaccia) i client non dovrebbero essere costretti a dipendere da interfacce che non utilizzano.
-d . dip(inversione della dipendenza )  afferma di dipendere dalle astrazioni, non dai concreti.

##### 12 fattori
la metodologia dei 12 fattori. Questa metodologia è pensata per applicazioni cloud-native, cioè facili da distribuire, scalare e mantenere.

I. Codebase
Regola: Una sola codebase per tutta l’app, sotto controllo di versione (Git, ad esempio), ma puoi fare molti deployment.
Significato: Tutti gli ambienti (sviluppo, test, produzione) partono dallo stesso codice, ma possono avere configurazioni e dati diversi.

II. Dipendenze
Regola: Dichiarare tutte le dipendenze in modo esplicito e isolarle (ad esempio con package manager, virtualenv, container).
Significato: L’app non “dipende” da librerie installate sul server: tutto ciò che serve è dichiarato nel progetto e replicabile ovunque.

III. Configurazione
Regola: Memorizza le informazioni di configurazione fuori dal codice, nell’ambiente (variabili d’ambiente, file di config).
Significato: Le informazioni sensibili o variabili tra ambienti (password, URL del DB, API key) non sono hard-coded nel codice.

IV. Backing Service
Regola: Tratta i backing service (DB, cache, sistemi di messaggistica, storage) come risorse esterne intercambiabili.
Significato: Puoi cambiare un DB o un servizio esterno senza modificare il codice, basta cambiare la configurazione.

V. Build, release, esecuzione
Regola: Separare chiaramente:
- Build → genera l’app pronta all’uso
- Release → combina build + configurazione
- Run → esecuzione vera e propria
Significato: Riduce errori: non fai build diverse per ogni ambiente, config e codice sono separati.

VI. Processi
Regola: L’app deve essere stateless, cioè i processi non conservano stato tra le richieste.
Significato: Lo stato (dati, sessioni) va in DB o cache esterni → facilita scalabilità e resilienza.

VII. Binding delle Porte
Regola: L’app espone i servizi tramite binding su una porta, senza dipendere da web server esterni specifici.
Significato: L’app è autonoma, chiunque può collegarsi alla porta esposta, ideale per container e cloud.

VIII. Concorrenza
Regola: Scalare applicazioni tramite processi indipendenti, non modificando il codice.
Significato: Aumentando richieste, puoi aggiungere più processi o container per gestire il carico senza cambiare l’app.

IX. Rilasciabilità
Regola: Avvii veloci e chiusure ordinate.
Significato: L’app deve partire rapidamente e chiudersi senza perdita di dati, facilitando deploy continui e rollback veloci.

X. Parità tra Sviluppo e Produzione
Regola: Mantieni gli ambienti di sviluppo, staging e produzione il più simili possibile.
Significato: Minori bug al deploy, test più affidabili → l’app si comporta uguale ovunque.

XI. Log
Regola: I log devono essere stream di eventi, non file locali.
Significato: Il logging è centralizzato (console, sistemi di aggregazione) e scalabile, perfetto per cloud.

XII. Processi di Amministrazione
Regola: Task di gestione (migrazione DB, backup, manutenzione) sono processi una tantum, non integrati nello stato dell’app.
Significato: Esegui operazioni di admin separatamente, senza interferire con i processi normali.

 i 12 fattori sono principi per creare applicazioni facili da distribuire, scalare e mantenere.
- Separano codice, configurazione e stato
- Permettono scalabilità orizzontale
- Rendono l’app portabile tra ambienti diversi

##### unit test
truttura 3A (Arrange, Act, Assert) negli unit test.

Gli **unit test** servono a verificare che una singola unità di codice (ad esempio un metodo) funzioni come previsto. 
La struttura 3A aiuta a scrivere test chiari e leggibili:

| Fase        | Cosa fai                                                                           |
| ----------- | ---------------------------------------------------------------------------------- |
| **Arrange** | Prepara l’oggetto da testare e eventuali servizi ausiliari (mock, dati, parametri) |
| **Act**     | Chiama il metodo o l’azione da testare                                             |
| **Assert**  | Controlla che il risultato o lo stato sia quello atteso                            |
###### java
Supponiamo di avere una classe semplice:

```java
public class Calculator {
    public int add(int a, int b) {
        return a + b;
    }
}
```

Un test con JUnit 5 usando 3A:

```java
import org.junit.jupiter.api.Test;
import static org.junit.jupiter.api.Assertions.assertEquals;

public class CalculatorTest {

    @Test
    void testAdd() {
        // Arrange
        Calculator calc = new Calculator();
        int x = 2;
        int y = 3;

        // Act
        int result = calc.add(x, y);

        // Assert
        assertEquals(5, result);
    }
}
```

Spiegazione:
* Arrange:  creo `Calculator` e definisco i numeri da sommare. preparo l'ggetto da testare
* **Act:** chiamo `add(x, y)`. chiamo il metodo da testare 
* **Assert:** verifico che il risultato sia 5. confronto il risultato del mio metodo con quello atteso

###### cs
Classe da testare:
```csharp
public class Calculator
{
    public int Add(int a, int b)
    {
        return a + b;
    }
}
```

Test con xUnit:
```csharp
using Xunit;

public class CalculatorTests
{
    [Fact]
    public void Add_ReturnsCorrectSum()
    {
        // Arrange
        var calc = new Calculator();
        int x = 2;
        int y = 3;

        // Act
        int result = calc.Add(x, y);

        // Assert
        Assert.Equal(5, result);
    }
}
```

**Nota sui mocks**
Se la classe dipende da servizi esterni (DB, API, ecc.), nel **Arrange** puoi usare **mock** per simulare quei servizi, così il test rimane **unitario** e isolato.


##### prinicpi di base di devOps
Definizione sintetica:
> DevOps è l’unione di **Persone, Processi e Prodotti** per ottenere il **rilascio continuo di valore** all’utente finale.

* **Persone:** sviluppatori, tester, operations, team di sicurezza, tutti collaborano.
* **Processi:** metodologie di sviluppo, testing, deploy e monitoraggio continui.
* **Prodotti / strumenti:** piattaforme e tool che automatizzano build, test, deploy, monitoraggio.

**Scopo:** ridurre il gap tra sviluppo (Dev) e gestione operativa (Ops), così che il software arrivi velocemente e in sicurezza all’utente.

i principi di base sono:

 1. **Agile Planning**
* Pianificazione iterativa, flessibile e basata sul valore reale per l’utente.
* Si lavora per **sprint** o cicli brevi, con feedback continui.
* Favorisce la priorità delle funzionalità più importanti e permette di adattarsi rapidamente ai cambiamenti.

2. **Continuous Integration (CI)**
* Ogni modifica del codice viene integrata nel repository principale più volte al giorno.
* Si eseguono build e test automatici ad ogni commit.
* Benefici:
  * Errori rilevati subito
  * Integrazione costante senza sorprese alla fine
  * Qualità del codice più alta

3. **Continuous Delivery (CD)**
* Estensione della CI: il codice **pronto al deploy** può essere rilasciato in produzione **in qualsiasi momento**, con un click o automaticamente.
* Obiettivo: ridurre i tempi tra sviluppo e rilascio, mantenendo stabilità e sicurezza.
* Spesso supportata da **pipeline di deploy automatiche** e test di regressione.

4. **Monitoring**
* Monitoraggio costante delle applicazioni in produzione: performance, errori, uso delle risorse, sicurezza.
* Serve a:
  * rilevare problemi rapidamente
  * ottenere dati sul comportamento reale degli utenti
  * supportare miglioramenti continui e feedback



**Come DevOps collega Persone, Processi e Prodotti**

| Elemento | Esempio pratico                                                                                              |
| -------- | ------------------------------------------------------------------------------------------------------------ |
| Persone  | Dev, Ops, QA, sicurezza lavorano insieme in team cross-funzionali                                            |
| Processi | CI/CD, test automatici, sprint agili, feedback continui                                                      |
| Prodotti | Jenkins, Azure DevOps, GitHub Actions, Docker, Kubernetes, strumenti di monitoring come Prometheus o Grafana |

##### pianificazione
overview, boards, backlogs .. non mi interessa
##### repos
qui si possono visualizzare i files e le versioni di essi. 
Nei corsi Azure DevOps si parla spesso di Azure Repos, il sistema di version control integrato in Azure DevOps Services (ex VSTS).

Azure Repos supporta sia:

  * **Git (distribuito)**
  * **Team Foundation Version Control (TFVC, centralizzato)**

Principi chiave che valgono sempre:
1. Tenere tutta la codebase sotto controllo di versione (uno dei 12 fattori del cloud).
2. Usare branching e merging per sviluppare funzionalità senza rompere il codice principale.
3. Integrare il VCS con **CI/CD** → ogni commit può innescare build e test automatici.

##### controllo di versione
Il controllo di versione (Version Control, VCS) è un sistema che traccia le modifiche al codice nel tempo, permettendo a più sviluppatori di lavorare insieme in modo ordinato.
**Benefici principali:**
* Puoi tornare indietro a versioni precedenti del codice
* Gestisci modifiche concorrenti di più sviluppatori
* Documenti la storia del progetto (chi ha fatto cosa e quando)
* Faciliti la collaborazione e la revisione del codice

**Git e GitHub**
Anche se Azure DevOps offre Repos, i principi restano gli stessi con GitHub:
  * Git è distribuito → ogni sviluppatore ha una copia completa del repository
  * Branch per funzionalità, bugfix, release
  * Merge / Pull Request → revisioni e approvazioni prima del merge nel main/master
Stessa logica dei principi Azure:** gestione versioni, collaborazione, CI/CD, release sicure

esempio pratico:
1. Sviluppatore crea un **branch** per una nuova funzionalità
2. Lavora sul codice, commit locali e poi push sul repo centrale (Azure Repos o GitHub)
3. Il sistema CI/CD esegue build e test automatici
4. Dopo revisione del codice, branch viene **mergiato** nel main
5. Release automatica o manuale in ambiente di test/prod

| Punto         | Azure DevOps                                    | GitHub / altri                                               |
| ------------- | ----------------------------------------------- | ------------------------------------------------------------ |
| Versionamento | Azure Repos (Git o TFVC)                        | Git distribuito                                              |
| Branching     | Feature branch, pull request                    | Stesso principio                                             |
| CI/CD         | Integrato nelle pipeline                        | Stesso principio, integrate con GitHub Actions, Jenkins, ecc |
| Principi      | Codice sotto controllo, storico, collaborazione | Identici, indipendentemente dallo strumento                  |


##### git
comandi (visti con oscar)
creando un progetto se si vuole che questo venga messo in un repository Git il comando è git init (da terminale posizionati dentro il progetto). con `git status` si verifica lo stato dei file modificati, con `git add .` si aggiunge un file ???????????? con `git commit -m "messaggio del primmo commit` si fa il commit. con `git push` si pusha. con `git checkout nome`  si cambia branch (e lo si crea se non esiste)...


per collegare la repo locale a una repo remota da terminale si fa 
`git remote add origin <URL_della_repo>` .. e poi con `git remote -v` vediamo cosa è stato fatto...vedremo che un *remoto* chiamato *origin* è stato collegato al mio repo locale....
mettiamo caso di aver sbagliato l'url della repo o di voler cambiare .. con 
`git remote set-url origin <URL_nuovo>` questo aggiorna l’URL del remote origin senza aggiungerne uno nuovo.
Poi finalmente si può fare il push `git push --set-upstream origin master`. “upstream branch” = branch remoto a cui il tuo branch locale punta. se facessimo solo git push, visto che il branch locale master non è ancora collegato a nessun branch remoto, Git non saprebbe dove mettere i commit su GitHub. cosi sa che deve mandarli al repository remoto (origin) sul branch master. 
ora Git invia i commit locali al nuovo repository remoto.
nei push futuri basterà fare git push.

al contrario per "scaricare" una repo remota in locale basta clonarla con git clone, essendo dentro la cartelal dove si vuole salvare la repo e con `git clone <URL_della_repo_remota`.

per modificare un file che si trova nella repo, mettiamo nell'origin.. mi posiziono nel branch master e pullo con `git pull origin master` .. per nn fare casini creo un branch `git checkout -b bugfix` ..modifico, salvo, aggiungo all'area commit `git add "nomefile`, poi committo `git commit -m "bug fixing` , build ed esecuzione in locale del codice modificato, aggiornamento del repository remoto mediante push... con `git push origin bugfix` con cui carico il mio branch bugfix sul remoto (*origin*)

##### comandi dotnet
finito git passiamo a comanndi dotnet , utili da sapere perche si scrivono nella #pipeline

comandi dotnet, come mappare quei comandi in **task YAML** per le pipeline, 
Esegui questi comandi localmente per assicurarti che la build funzioni: ogni comando sarà poi trasformato in uno o più task nella pipeline.
* Nella cartella della solution (contiene `.sln`):
```bash
dotnet test               # compila ed esegue i test
```
* Nella cartella del progetto (contiene .csproj):
```bash
dotnet build              # compila il progetto
dotnet run                # esegue (compila se necessario)
```
* Opzioni di configurazione:
```bash
dotnet build --configuration Debug
dotnet build --configuration Release
```
* Eseguire senza ricompilare (utile in pipeline quando hai già buildato):
```bash
dotnet run --configuration Release --no-build --project <nome-progetto>
```

> Regola pratica: assicurati di poter eseguire tutti i comandi da terminale. Solo così li potrai mappare agevolmente nelle pipeline.

##### dai comandi al task yaml
Concetto chiave: **mappare ogni comando terminale a un task** nella pipeline. 
Azure Pipelines *fornisce task preconfezionati* (es. `DotNetCoreCLI@2`) che semplificano la mappatura.
Esempio: se localmente fai `dotnet build` → in YAML userai un task `DotNetCoreCLI@2` con `command: build`.
**Cosa sono i Task delle Pipeline?** : Un task è un’operazione automatica che Azure esegue sulla macchina di build. Esempi di task tipici:
- Installare SDK o runtime necessari (es. .NET, Node, Java…)
- Compilare (dotnet build)
- Eseguire test (dotnet test)
- Pubblicare (dotnet publish)
- Copiare o comprimere file
- Eseguire script Bash/Powershell
- Preparare la macchina (configurazioni, prerequisiti…)

Azure DevOps ti dà centinaia di task già pronti, descritti nella documentazione:  https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/?view=azure-devops
Questi task sono modulari: li combini e ottieni l'intera pipeline di build.

La pipeline non gira sul tuo PC: Azure crea una macchina virtuale temporanea che dura solo per la durata della pipeline.
I task servono esattamente a:
- Installare tutto ciò che serve (SDK, pacchetti, tool)
- Configurare l’ambiente
- Eseguire comandi
- Ottimizzare, comprimere, preparare i file
- Pubblicare gli artefatti

> Quando la pipeline finisce, la macchina viene eliminata.

Per questo serve un file YAML completo e autosufficiente.

#####  Struttura base di un file pipeline YAML
Elementi principali:
* `pool` — agent (Windows/Linux) che esegue i job, dice quale macchina usare.
* `variables` — variabili riutilizzabili, riferite come `$(nomeVariabile)`
* `steps` — elenco dei task da eseguire.
* condizioni
* trigger(quando parte la pipeline)

Il file YAML viene salvato nel repository esattamente come il codice.
Perché?
Chiunque modifica il progetto modifica anche la pipeline...
La pipeline segue l’evoluzione del codice
(cambio codice → cambio pipeline)
Questo è ciò che si intende per:
"in tal modo è tutto autoconsistente".
Il codice e l’ambiente di build viaggiano insieme.

###### esempio
```yaml
pool:
  vmImage: 'ubuntu-latest'

variables:
  buildConfiguration: 'Release'

steps:
- task: DotNetCoreCLI@2
  displayName: 'Restore'
  inputs:
    command: 'restore'
    projects: '**/*.csproj'

- task: DotNetCoreCLI@2
  displayName: 'Build'
  inputs:
    command: 'build'
    projects: '**/*.csproj'
    arguments: '--configuration $(buildConfiguration)'

- task: DotNetCoreCLI@2
  displayName: 'Run tests'
  inputs:
    command: 'test'
    projects: '**/*Tests/*.csproj'
    arguments: '--configuration $(buildConfiguration)'
```


##### Produzione e pubblicazione artefatti (build artifacts)
Tipico workflow: build → publish (dotnet publish produce pacchetto) → pubblica artifact nella pipeline.
Il processo di trasformazione in artefatto serve a prendere il codice e renderlo eseguibile/consumabile in un ambiente esterno.

###### esempio
Esempio pratico (estratto e commentato):
```yaml
variables:
  buildConfiguration: 'Release'
  artifactStagingDirectory: '$(Build.ArtifactStagingDirectory)/$(buildConfiguration)'

steps:
# Restore / Build / Test omessi per brevità

# Publish: produce l'output pronto da rilasciare (es. zip)
- task: DotNetCoreCLI@2
  displayName: 'Publish the project - $(buildConfiguration)'
  inputs:
    command: 'publish'
    projects: '**/*.csproj'
    publishWebProjects: false
    arguments: '--no-build --configuration $(buildConfiguration) --output $(artifactStagingDirectory)'
    zipAfterPublish: true

# Pubblica gli artifact prodotti nella pipeline
- task: PublishBuildArtifacts@1
  displayName: 'Publish Artifact: drop'
  inputs:
    PathtoPublish: '$(artifactStagingDirectory)'
    ArtifactName: 'drop'
    publishLocation: 'Container'
  condition: succeeded()
```
Note:
* `$(Build.ArtifactStagingDirectory)` è il percorso standard dell’agent per preparare artefatti.
* `zipAfterPublish: true` crea file zip utili per release/deploy.


##### Release dell’artefatto (deploy)
Quando nella pipeline di build produci un artefatto (ad esempio il tuo progetto compilato o un pacchetto zip):
- L’artefatto rimane registrato nella pipeline di Azure DevOps
- Non è ancora “in produzione” o su una macchina esterna
- Per usarlo in un ambiente reale (server, App Service, container, VM, Kubernetes…) devi fare il deploy

> Il deploy è quindi la fase in cui il software viene “portato” dall’ambiente di build all’ambiente target (che tipicamente è un conteiner o docker)

Gli artefatti pubblicati nella pipeline di build (ad esempio il tuo progetto compilato) possono essere rilasciati (deploy) in ambienti target mediante:
* **Release pipeline** (classic) o
* **multi-stage pipeline YAML** (consigliato per infrastrutture moderne, automatizza tutto in un unico file, versione compresa).

Per poter deployare su risorse esterne (VM, App Service, Kubernetes) devi creare una **service connection** (un canale sicuro che permette alla pipeline di accedere a risorse esterne (Azure, VM, Kubernetes…)).
in modo tale da non dover mettere username/password nello yaml, per dire alla pipeline di usare credenziali gia autorizzate
-> permette alla pipeline di pubblicare gli artefatti nel target corretto. 

https://docs.microsoft.com/en-us/learn/modules/create-release-pipeline/5-deploy-to-appservice 

##### service connection 
#serviceconnection
Esempio di passi per creare una [[2025-11-24 DEFINIZIONI#Service Connection|service connection]] (concetto):
1. In Azure DevOps → Project settings → Service connections
2. Crea connessione a Azure Resource Manager (service principal). ARM famoso..
3. Usala nei task di deploy (ad es. `AzureWebApp@1`, `AzureRmWebAppDeployment@4`, `Kubernetes@1`).

Documentazione Microsoft: esiste una guida passo passo per creare la service connection e configurare permessi.


#### Variabili e loro uso
* Le variabili definite nella sezione `variables:` si usano con `$(nome)` nel file YAML.
* Per passare segreti e password usa **variable groups** o **Azure Key Vault**.

Esempio:

```yaml
variables:
  buildConfiguration: 'Release'
  appName: 'myapp'

steps:
- script: echo "Deploying $(appName) in $(buildConfiguration)"
```


#### Uso dei template (riuso di YAML)

I template sono come funzioni riutilizzabili. Utilizzo tipico: non duplicare le stesse step per Debug/Release; crea un template parametrizzato.

* Nel template (`templates/pipeline-build.yml`), si usa `parameters`:

```yaml
# templates/pipeline-build.yml
parameters:
  - name: configuration
    type: string
    default: 'Release'

steps:
- task: DotNetCoreCLI@2
  inputs:
    command: 'build'
    arguments: '--configuration ${{ parameters.configuration }}'
```

* Nel file principale si richiama il template:

```yaml
variables:
  buildConfiguration: 'Release'

steps:
- template: templates/pipeline-build.yml
  parameters:
    configuration: $(buildConfiguration)
```

Differenze importanti:

* `variables` → si usano con `$(...)`
* `parameters` → si usano con `${{ parameters.x }}` e sono valutati al momento della compilazione del YAML

Vantaggio: puoi chiamare lo stesso template con `Debug` e `Release` per produrre artefatti diversi senza duplicare logica.

#### Buone pratiche e suggerimenti operativi

* **Testa localmente**: prima di scrivere la pipeline, assicurati che `dotnet build`, `dotnet test`, `dotnet publish` funzionino da terminale o script.
* **Stage separati**: usa build → test → publish → deploy in stage distinti (multi-stage YAML).
* **Artefatti nominati**: includi la configurazione o la versione nel percorso artifact per chiarezza `$(Build.BuildNumber)` o `$(Build.SourceBranchName)`.
* **Condizioni**: usa `condition: succeeded()` per task che devono eseguire solo se i pass precedenti sono andati a buon fine.
* **Caching**: abilita caching dei pacchetti NuGet per velocizzare le build.
* **Security**: non hardcodare segreti nel YAML; usa variable groups/Key Vault.
* **Pipeline as code**: tieni il file YAML nel repository e versione insieme al codice.

---

#### Risorse utili (concetto)

* Catalogo task Azure DevOps → cerca `DotNetCoreCLI`, `PublishBuildArtifacts`, `AzureWebApp`, `Kubernetes`, ecc.
* Marketplace pipeline templates → esempi pronti da importare (github/azure pipelines marketplace)

---

#### Esempio completo

Una pipeline che fa restore, build, test, publish e produce artifact:
```yaml
trigger:
- main

pool:
  vmImage: 'windows-latest'

variables:
  buildConfiguration: 'Release'
  artifactPath: '$(Build.ArtifactStagingDirectory)/$(buildConfiguration)'

stages:
- stage: Build
  jobs:
  - job: BuildJob
    steps:
    - task: DotNetCoreCLI@2
      displayName: 'Restore'
      inputs:
        command: 'restore'
        projects: '**/*.csproj'

    - task: DotNetCoreCLI@2
      displayName: 'Build'
      inputs:
        command: 'build'
        projects: '**/*.csproj'
        arguments: '--configuration $(buildConfiguration)'

    - task: DotNetCoreCLI@2
      displayName: 'Test'
      inputs:
        command: 'test'
        projects: '**/*Tests/*.csproj'
        arguments: '--configuration $(buildConfiguration)'

    - task: DotNetCoreCLI@2
      displayName: 'Publish'
      inputs:
        command: 'publish'
        projects: '**/*.csproj'
        arguments: '--configuration $(buildConfiguration) --output $(artifactPath)'
        zipAfterPublish: true

    - task: PublishBuildArtifacts@1
      displayName: 'Publish Artifact'
      inputs:
        PathtoPublish: '$(artifactPath)'
        ArtifactName: 'drop'
```

---

[^1]: 
