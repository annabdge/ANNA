---
cssclasses:
  - martedi
tags:
  - servizi
  - deploy
  - deployment
  - gateway
  - frontend
  - docker
  - URL
  - "#containerport"
  - "#targetport"
  - "#port"
---


martedi
# psn
dal wiki 
Esiste una sezione ufficiale del **Polo Strategico Nazionale (PSN)** dedicata ai **requisiti tecnici e documentazione** per la migrazione e l‚Äôinstallazione degli applicativi della Pubblica Amministrazione. Ecco i riferimenti principali:

### üìÑ **Documentazione tecnica e requisiti degli applicativi**
Pagina ufficiale: [Documentazione PSN](https://www.polostrategiconazionale.it/obiettivo-cloud/documentazione/ "https://www.polostrategiconazionale.it/obiettivo-cloud/documentazione/")
In questa sezione trovi:
*   Listino PSN (giugno 2025)** con la descrizione dei servizi cloud disponibili.
*   Caratteristiche tecniche** dei servizi previsti dalla concessione.
*   Modelli e moduli** per l‚Äôadesione.
*   Nomina del Responsabile del trattamento dei dati personali.
* * *
### üìò **Linee guida per la migrazione degli applicativi**

üîó PDF ufficiale: [Allegato 2 ‚Äì Linee guida per la migrazione](https://www.polostrategiconazionale.it/app/uploads/2025/03/Allegato-2-Linee-guida-per-la-compilazione-della-domanda-e-per-la-migrazione.pdf "https://www.polostrategiconazionale.it/app/uploads/2025/03/allegato-2-linee-guida-per-la-compilazione-della-domanda-e-per-la-migrazione.pdf")
Contiene:
*   Requisiti per **server fisici e macchine virtuali migrabili**.
*   Modalit√† di **attestazione tecnica** e documentazione a supporto.
*   **Scenari di ammissibilit√†** per la migrazione.
*   **Questionario di assessment** per valutare lo stack tecnologico.
*   Indicazioni su **container, PaaS, database** e infrastrutture sottostanti [[2]](https://www.polostrategiconazionale.it/app/uploads/2025/03/Allegato-2-Linee-guida-per-la-compilazione-della-domanda-e-per-la-migrazione.pdf "https://www.polostrategiconazionale.it/app/uploads/2025/03/allegato-2-linee-guida-per-la-compilazione-della-domanda-e-per-la-migrazione.pdf").
* * *
### üîß **Tipologie di migrazione disponibili**
üîó Servizi di migrazione PSN* [Servizi di migrazione](https://www.polostrategiconazionale.it/soluzioni/servizi-di-migrazione/ "https://www.polostrategiconazionale.it/soluzioni/servizi-di-migrazione/")
Sono previste tre modalit√†:
1.  **Re-Host**: spostamento diretto senza modifiche.
2.  **Re-Platform**: adattamento parziale all‚Äôambiente cloud.
3.  **Re-Architect**: trasformazione completa in cloud-native.
Tutte le migrazioni seguono il metodo **EMG2C**: _Explore ‚Üí Make ‚Üí Go To Cloud_ [[3]](https://www.polostrategiconazionale.it/soluzioni/servizi-di-migrazione/ "https://www.polostrategiconazionale.it/soluzioni/servizi-di-migrazione/").

* * *






# deploy
Deploy di part-numbers 
funzionamento del servizio. 
swagger funziona solo con il port-forward `kubectl port-forward pod/afm-mn-partnumbers 5011:8080`
NONOSTANTE il pod sembri essere in ascolto sulla porta 5011. con 5011:5001 non funziona, tantomeno con l'url [https://temp.afm.vvf.priv/api/part-number/swagger/index.html](https://temp.afm.vvf.priv/api/part-number/swagger/index.html)
questo va ricercato nei file di configurazione, c'√® un problema di path . 

nel fratttempo dopo aver fatto un test di funzionamento del servizio (con un port-forward) ho notato che c'√® un "disallineamento" tra quello che Kubernetes crede (5011) e quello che l'applicazione fa realmente (8080). 
La ConfigMap (bff-gateway-config) √® il posto pi√π probabile dove questo cambiamento √® stato iniettato.


# Analisi dell'Architettura dei Servizi "vvf"

I documenti di configurazione forniti descrivono un'architettura a microservizi distribuita su un cluster Kubernetes all'interno del namespace `vvf`. Il sistema √® orchestrato attorno a un componente centrale, un **BFF (Backend for Frontend) Gateway**, che gestisce il routing, l'autenticazione e l'arricchimento del contesto utente per le chiamate verso i servizi a valle. L'autenticazione √® delegata a un'istanza di Keycloak, con una chiara separazione tra endpoint pubblici e interni per una maggiore sicurezza.

L'analisi rivela due strategie parallele per l'esposizione dei servizi all'esterno: una attraverso il BFF Gateway, che implementa logiche applicative e di sicurezza avanzate, e l'altra tramite un **Ingress temporaneo** basato su Kong, che espone direttamente alcuni degli stessi microservizi. Questa duplicazione, evidenziata dal nome `temp-ingress`, suggerisce una fase di transizione, sviluppo o test.

Un punto critico emerso dalla configurazione del BFF Gateway √® l'**abilitazione temporanea di impostazioni SSL insicure**, segnalata esplicitamente da commenti nel codice. Queste configurazioni, che bypassano la validazione dei certificati, rappresentano un rischio significativo per la sicurezza e sono state contrassegnate per essere disabilitate prima del passaggio in produzione. L'infrastruttura si avvale di tecnologie come Azure Container Registry per le immagini Docker e Redis Sentinel per la gestione delle sessioni utente.

#### 1. Panoramica dell'Architettura Applicativa
Il sistema √® composto da una serie di microservizi containerizzati che collaborano per fornire funzionalit√† complesse. L'architettura √® centrata sul pattern **Backend for Frontend (BFF)**, dove un gateway specifico funge da intermediario tra le applicazioni client (es. un'interfaccia web) e i servizi interni.

I componenti principali identificati sono:
- **BFF Gateway**: Un servizio basato su Spring Cloud Gateway che agisce come unico punto di ingresso (o uno dei punti principali) per le richieste API.
- **Servizi Backend**: Microservizi specializzati, tra cui:
    - `afm-mn-partnumbers-service`: Gestione dei "part number".
    - `profile-manager-service`: Gestione dei profili utente.
    - `afm-mn-technicalpubs-service`: Gestione delle pubblicazioni tecniche.
    - `afm-ms-backend-service`: Servizio backend generico.
    - `afm-mn-serialnumbers-service`: Gestione dei numeri di serie.
- **Sistema di Autenticazione**: Un'istanza di Keycloak dedicata.
- **Frontend**: Un'applicazione web (`vvf-frontend-service`) che interagisce con i servizi tramite l'infrastruttura di routing.
- **Integrazione Esterna**: Un servizio legacy o esterno raggiungibile all'indirizzo `https://172.22.0.169:83`.

Tutti i componenti sono ospitati nel namespace Kubernetes `vvf`, garantendo un isolamento logico.

#### 2. Componenti Chiave e Configurazioni

##### 2.1. BFF Gateway
Il BFF Gateway √® il fulcro dell'architettura per l'accesso API. √à configurato tramite il ConfigMap `bff-gateway-config`.

**Routing e Filtri** Il gateway instrada le richieste in base al percorso URL verso i servizi interni corrispondenti. Applica inoltre una serie di filtri a ogni richiesta:

|   |   |   |   |
|---|---|---|---|
|ID Rotta|Percorso (Predicate)|URI di Destinazione|Filtri Applicati|
|`profile-api`|`/api/profile-api/**`|`http://profile-manager-service.vvf.svc.cluster.local`|`RewritePath`, `TokenRelay`, `AddUserContext`|
|`part-number-swagger`|`/api/part-number/swagger/**`|`http://afm-mn-partnumbers-service`|`RewritePath`, `TokenRelay`, `AddUserContext`|
|`part-number-api`|`/api/part-number/**`|`http://afm-mn-partnumbers-service`|`RewritePath`, `TokenRelay`, `AddUserContext`|
|`technical-pubs-swagger`|`/api/technical-pubs/swagger/**`|`http://afm-mn-technicalpubs-service`|`RewritePath`, `TokenRelay`, `AddUserContext`|
|`technical-pubs-api`|`/api/technical-pubs/**`|`http://afm-mn-technicalpubs-service`|`RewritePath`, `TokenRelay`, `AddUserContext`|
|`afm-ms-backend-api`|`/api/afm-ms-backend/**`|`http://afm-ms-backend-service`|`RewritePath`, `TokenRelay`, `AddUserContext`|
|`rearchitect`|`/rearch/**`|`https://172.22.0.169:83`|`StripPrefix`, `RewriteLocationHeader`, `AddUserContext`|

**Arricchimento del Contesto Utente (**`**AddUserContext**`**)** Un filtro personalizzato denominato `AddUserContext` intercetta le richieste autenticate e aggiunge informazioni sull'utente agli header HTTP prima di inoltrarle ai servizi a valle. Questo astrae la logica di gestione dell'identit√† dai singoli microservizi. Gli header aggiunti includono:

- `X-AFM-User-Id`: ID univoco dell'utente.
- `X-User-Departments`: Reparti di appartenenza dell'utente.
- Il filtro pu√≤ anche includere il Codice Fiscale, mentre username ed email sono esplicitamente disabilitati.

**Gestione delle Sessioni** La gestione delle sessioni utente √® affidata a Redis, configurato in modalit√† Sentinel per l'alta disponibilit√†.

- **Namespace Redis**: `afm-bff-session`
- **Master Sentinel**: `mymaster`
- **Nodi Sentinel**: `100.64.59.141:26379`
- **Cookie di Sessione**:
    - **Nome**: `AFM_SESSION`
    - **Dominio**: `.afm.vvf.priv`
    - **Attributi**: `Secure`, `HttpOnly`, `SameSite=None`

##### 2.2. Servizio `afm-mn-partnumbers`

Questo servizio √® un esempio rappresentativo di un microservizio backend nell'architettura.

- **Deployment**: La sua configurazione (`afm-mn-partnumbers`) prevede una singola replica.
- **Immagine**: L'immagine del container √® `afmvvf.azurecr.io/mn/partnumbers:latest`, ospitata su Azure Container Registry.
- **Porta**: Il container espone la porta `5011`.
- **Configurazione**: Utilizza un ConfigMap (`appsettings-partnumbers`) per iniettare il file `appsettings.json` nel percorso `/app/appsettings.json`.
- **Storage Persistente**: Monta un volume persistente (`afm-mn-partnumbers-pvc`) sul percorso `/mnt/config`, indicando la necessit√† di memorizzare dati in modo durevole.
- **Esposizione Interna**: Il servizio Kubernetes (`afm-mn-partnumbers-service`) di tipo `ClusterIP` espone il servizio sulla porta `80` all'interno del cluster, inoltrando il traffico alla porta `5011` del container.

##### 2.3. Autenticazione e Autorizzazione (Keycloak)

Il sistema utilizza Keycloak come Identity and Access Management provider.

- **Realm**: `vvf`
- **Client ID**: `vvf_client`
- **Flusso di Autenticazione**: Il BFF Gateway gestisce il flusso OAuth2/OIDC. √à configurato con una doppia URL per Keycloak:
    - **URL Pubblico**: `https://keycloak.afm.vvf.priv` (usato per le interazioni con il browser, come i reindirizzamenti per il login).
    - **URL Interno**: `http://keycloak-service.keycloak-vvf.svc.cluster.local` (usato per la comunicazione server-to-server all'interno del cluster, come la validazione dei token e il recupero delle chiavi pubbliche - JWK Set URI).
- **Gestione dei Token**: Il gateway valida i token JWT ricevuti e, tramite il filtro `TokenRelay`, li propaga in modo sicuro ai servizi backend, consentendo a questi ultimi di agire per conto dell'utente autenticato.

### 3. Esposizione Esterna e Gestione del Traffico

L'analisi dei file di configurazione rivela un duplice approccio all'esposizione dei servizi all'esterno del cluster.

##### 3.1. Ingress Temporaneo (`temp-ingress`)

Un oggetto Ingress denominato `temp-ingress` √® configurato per gestire il traffico in entrata.

- **Ingress Controller**: Utilizza la classe `kong`, indicando che Kong API Gateway √® impiegato come reverse proxy e API gateway perimetrale.
- **Host**: Il traffico √® gestito per il dominio `temp.afm.vvf.priv`.
- **TLS**: La terminazione TLS √® attiva e configurata tramite il secret Kubernetes `afm-tls-secret`.
- **Regole di Routing**: Questo Ingress espone direttamente diversi servizi:

|   |   |   |
|---|---|---|
|Percorso|Servizio di Backend|Porta|
|`/`|`vvf-frontend-service`|`8080`|
|`/api/part-number`|`afm-mn-partnumbers-service`|`80`|
|`/api/serial-number`|`afm-mn-serialnumbers-service`|`80`|
|`/api/technical-pubs`|`afm-mn-technicalpubs-service`|`80`|
|`/api/afm-ms-backend`|`afm-ms-backend-service`|`80`|

##### 3.2. Coesistenza dei Punti di Accesso

La configurazione del `temp-ingress` espone direttamente API come `/api/part-number`, che sono anche gestite dal BFF Gateway. Questa coesistenza implica due percorsi distinti per accedere agli stessi servizi:

1. **Via BFF Gateway**: Un percorso "intelligente" che applica logiche di sessione, inoltro di token e arricchimento del contesto utente.
2. **Via** `**temp-ingress**`: Un percorso diretto che espone il servizio backend senza i filtri e le logiche applicative del BFF.

Il nome `temp-ingress` suggerisce fortemente che questa configurazione sia temporanea, probabilmente utilizzata per scopi di sviluppo, test diretti sulle API o durante una migrazione architetturale. Tuttavia, questa duplicazione potrebbe portare a inconsistenze nelle policy di sicurezza e a una maggiore complessit√† per i client.

### 4. Considerazioni sulla Sicurezza 

##### 4.1. Configurazioni SSL Insicure

La configurazione del BFF Gateway contiene avvisi espliciti riguardo a impostazioni di sicurezza SSL allentate, abilitate a scopo di test.
- **Avviso**: `‚ö†Ô∏è TEMPORANEAMENTE ABILITATO PER TEST`
- **Impostazioni Coinvolte**:
    - `ssl.insecure-enabled: true`
    - `cloud.gateway.httpclient.ssl.use-insecure-trust-manager: true`
- **Rischio**: Queste direttive disabilitano la convalida dei certificati TLS, rendendo le comunicazioni tra il gateway e i servizi interni (o esterni come `172.22.0.169:83`) vulnerabili ad attacchi Man-in-the-Middle (MITM). √à imperativo disabilitarle in un ambiente di produzione, come indicato dal commento `TODO`.

##### 4.2. Gestione dei Secret

La configurazione del client OAuth2 per Keycloak referenzia il client secret tramite una variabile (`${KEYCLOAK_CLIENT_SECRET}`). Questa √® una best practice, poich√© evita di inserire credenziali sensibili direttamente nei file di configurazione. Il valore viene probabilmente iniettato nel container tramite un Secret di Kubernetes o una variabile d'ambiente.

##### 4.3. CORS (Cross-Origin Resource Sharing)

La policy CORS √® abilitata e configurata per consentire richieste dai seguenti domini:
- `http://localhost:4200`
- `https://fleet.afm.vvf.priv`
- `http://host.docker.internal`

Questa configurazione supporta lo sviluppo locale (tipicamente per framework come Angular, React, Vue) e l'applicazione web di produzione ospitata su `fleet.afm.vvf.priv`.




### VVF_AFM_PartNumbers 
repository clonato in C:\Progetti

Ecco la spiegazione dettagliata del perch√© vedi questa discrepanza e dove viene decisa la porta reale:

##### Perch√© "describe pod" dice 5011?
Quello che leggi eseguendo il `describe pod` √® semplicemente la **dichiarazione** che √® stata scritta nel file YAML del Deployment (sotto la voce `containerPort`).

- In Kubernetes, la `containerPort` √® principalmente informativa: serve a documentare quale porta dovrebbe essere usata, ma non "forza" l'applicazione ad aprirla.
- Se l'applicazione nel codice √® impostata per girare sulla 8080, essa aprir√† la 8080 anche se nel Deployment hai scritto 5011.

##### Chi ha deciso la porta 8080? (Il file responsabile)

L'**Ingress non c'entra**, poich√© l'Ingress si occupa solo di gestire il traffico che arriva dall'esterno verso il Service. La decisione della porta avviene "pi√π in profondit√†":

- **ConfigMap:** √à il sospettato principale. Le ConfigMap vengono usate per passare variabili d'ambiente all'applicazione. Ad esempio, in un'app .NET, una variabile come `ASPNETCORE_URLS=http://+:8080` forza l'app a ignorare qualsiasi altra impostazione e ad ascoltare sulla 8080.
- File di configurazione interni (appsettings.json / application.properties):** Questi file si trovano dentro il codice dell'applicazione (nella cartella `Application` o `Infrastructure` menzionata nelle fonti). Se nel codice √® scritto di usare la 8080, l'app user√† quella.
- **Dockerfile:** Il comando di avvio (`ENTRYPOINT` o `CMD`) potrebbe contenere un parametro esplicito (es: `--server.port=8080`) che sovrascrive tutto il resto.

##### La catena di errore nel tuo caso
Dalle fonti emerge che c'√® stata molta confusione perch√© stavano cambiando **troppe porte contemporaneamente** (80, 5011, 8080). La situazione che hai scoperto √® questa:

1. L'App (dentro il container) ascolta sulla 8080 (lo conferma il fatto che il portforward con porta remota = 8080 funzioni) 
2. Il Pod (dichiarazione) dice erroneamente 5011 ( #containerport nel deployment.yaml)
3. Il Service (ClusterIP) riceve sulla **80** ( #port ) e cerca di inviare alla **5011** ( #targetport) (ma fallisce perch√© l'app √® sulla 8080).

##### Cosa andr√† corretto?
Per far funzionare tutto senza dover usare ogni volta il port-forward manuale sulla 8080: 
> aggiorna il **Service** affinch√© la sua `targetPort` sia **8080** invece di 5011.

In sintesi: Il tuo test ha dimostrato che c'√® un "disallineamento" tra quello che Kubernetes crede (5011) e quello che l'applicazione fa realmente (8080). 
La ConfigMap √® il posto pi√π probabile dove questo cambiamento √® stato iniettato.

L'analogia della targa sulla porta:
√à come se sulla porta di un ufficio ci fosse una targa con scritto "Stanza 5011" (il describe pod), ma se provi a bussare non risponde nessuno. Se per√≤ bussi alla porta accanto, la **8080**, trovi l'impiegato al lavoro. La targa √® sbagliata, ma l'impiegato ha deciso di sedersi nell'altra stanza perch√© cos√¨ √® scritto nel suo contratto di lavoro (la ConfigMap).



